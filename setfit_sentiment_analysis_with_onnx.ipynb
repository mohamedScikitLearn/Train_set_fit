{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Sentiment Analysis with SetFit + ONNX Export\n",
    "\n",
    "This notebook walks through:\n",
    "1. **Training** a sentiment classifier with only ~10 examples per class using [SetFit](https://github.com/huggingface/setfit)\n",
    "2. **Exporting** the trained model to [ONNX](https://onnx.ai/) for fast, portable inference\n",
    "3. **Running inference** with ONNX Runtime — no PyTorch needed in production\n",
    "\n",
    "**Requirements:** Python 3.9+, ~5 minutes on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install setfit datasets torch transformers onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What is SetFit?\n",
    "\n",
    "**SetFit** (Sentence Transformer Fine-tuning) is a framework for **few-shot text classification** by Hugging Face.\n",
    "\n",
    "### Why SetFit over traditional fine-tuning?\n",
    "\n",
    "| Feature | SetFit | Traditional Fine-tuning |\n",
    "|---------|--------|------------------------|\n",
    "| Training examples needed | **8–64 per class** | Hundreds to thousands |\n",
    "| Training time | **1–5 min on CPU** | Hours on GPU |\n",
    "| Prompts required | No | Sometimes |\n",
    "\n",
    "### How it works (two phases)\n",
    "\n",
    "1. **Contrastive fine-tuning** — Generates pairs of texts. Same-class pairs are pushed closer in embedding space; different-class pairs are pushed apart.\n",
    "2. **Head training** — A logistic regression is trained on the resulting embeddings.\n",
    "\n",
    "```\n",
    "Text → [ Sentence Transformer ] → Embedding (384-dim) → [ Logistic Regression ] → Label\n",
    "            (fine-tuned)                                    (trained on embeddings)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from setfit import SetFitModel, SetFitTrainer\n",
    "from sentence_transformers.losses import CosineSimilarityLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Prepare the Training Data\n",
    "\n",
    "We only need **~10 examples per class** — that's the power of few-shot learning.\n",
    "\n",
    "Our task: classify text as **positive** (0), **negative** (1), or **neutral** (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Few-shot training data: 10 examples per class (30 total).\n",
    "# SetFit generates contrastive pairs from these to learn the\n",
    "# decision boundaries between classes.\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "training_data = {\n",
    "    \"text\": [\n",
    "        # --- Positive (label 0) ---\n",
    "        \"I absolutely love this product, it exceeded my expectations!\",\n",
    "        \"The customer service was outstanding and very helpful.\",\n",
    "        \"Best purchase I've made all year, highly recommend it.\",\n",
    "        \"The quality is amazing for the price, very satisfied.\",\n",
    "        \"This app is fantastic, it makes everything so much easier.\",\n",
    "        \"I'm impressed by how well this works, great job!\",\n",
    "        \"The food was delicious and the atmosphere was wonderful.\",\n",
    "        \"Excellent experience from start to finish, will come back.\",\n",
    "        \"This is exactly what I needed, works perfectly.\",\n",
    "        \"I can't stop recommending this to all my friends.\",\n",
    "\n",
    "        # --- Negative (label 1) ---\n",
    "        \"Terrible product, broke after just two days of use.\",\n",
    "        \"The worst customer service experience I've ever had.\",\n",
    "        \"Complete waste of money, I want a full refund.\",\n",
    "        \"The quality is awful, nothing like what was advertised.\",\n",
    "        \"This app crashes constantly, it's unusable.\",\n",
    "        \"I'm extremely disappointed with this purchase.\",\n",
    "        \"The food was cold and the service was incredibly slow.\",\n",
    "        \"Horrible experience, I will never shop here again.\",\n",
    "        \"This doesn't work at all, total scam.\",\n",
    "        \"I regret buying this, it's cheaply made junk.\",\n",
    "\n",
    "        # --- Neutral (label 2) ---\n",
    "        \"The package arrived on the expected delivery date.\",\n",
    "        \"It works as described, nothing more nothing less.\",\n",
    "        \"The product is okay, it serves its basic purpose.\",\n",
    "        \"Standard quality for this price range.\",\n",
    "        \"I received the item and it matches the description.\",\n",
    "        \"It's an average product, does what it's supposed to do.\",\n",
    "        \"The service was normal, no complaints or praise.\",\n",
    "        \"Delivery was on time and the item was as expected.\",\n",
    "        \"It's fine for everyday use, nothing special though.\",\n",
    "        \"The product meets the basic requirements I had.\",\n",
    "    ],\n",
    "    \"label\": [0] * 10 + [1] * 10 + [2] * 10,\n",
    "}\n",
    "\n",
    "# Human-readable label mapping\n",
    "ID_TO_LABEL = {0: \"positive\", 1: \"negative\", 2: \"neutral\"}\n",
    "\n",
    "# Convert to HuggingFace Dataset (required by SetFit)\n",
    "train_dataset = Dataset.from_dict(training_data)\n",
    "\n",
    "print(f\"Training samples : {len(train_dataset)}\")\n",
    "print(f\"Classes          : {list(ID_TO_LABEL.values())}\")\n",
    "print(f\"Samples per class: {len(train_dataset) // len(ID_TO_LABEL)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Train the Model\n",
    "\n",
    "We use `all-MiniLM-L6-v2` as the base sentence transformer — small (80 MB),\n",
    "fast, and produces 384-dimensional embeddings.\n",
    "\n",
    "**Key parameters:**\n",
    "| Parameter | What it does |\n",
    "|---|---|\n",
    "| `num_iterations` | How many contrastive text pairs to generate per class combination. More = better boundaries. |\n",
    "| `num_epochs` | Training passes over the generated pairs. 1 is usually enough for few-shot. |\n",
    "| `batch_size` | Pairs processed per gradient step. |\n",
    "| `loss_class` | `CosineSimilarityLoss` pulls same-class embeddings together and pushes different-class apart. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained sentence transformer.\n",
    "# SetFit will fine-tune its weights so that texts with the same\n",
    "# sentiment produce similar embeddings.\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    batch_size=16,\n",
    "    num_iterations=20,   # 20 pairs per class combo -> 20 * C(3,2) = 60 pairs\n",
    "    num_epochs=1,\n",
    ")\n",
    "\n",
    "# ~1-3 minutes on CPU\n",
    "trainer.train()\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Test the Model\n",
    "\n",
    "Evaluate on examples the model has **never** seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = [\n",
    "    # Positive\n",
    "    (\"This restaurant has the best pasta I've ever tasted!\", \"positive\"),\n",
    "    (\"I'm so happy with my new phone, it's incredible.\", \"positive\"),\n",
    "    (\"The team did an amazing job on this project.\", \"positive\"),\n",
    "    # Negative\n",
    "    (\"The hotel room was dirty and the staff was rude.\", \"negative\"),\n",
    "    (\"This software is full of bugs, very frustrating.\", \"negative\"),\n",
    "    (\"I waited 3 hours and nobody helped me.\", \"negative\"),\n",
    "    # Neutral\n",
    "    (\"The meeting is scheduled for 3 PM tomorrow.\", \"neutral\"),\n",
    "    (\"The store opens at 9 AM and closes at 6 PM.\", \"neutral\"),\n",
    "    (\"I ordered the blue version of the product.\", \"neutral\"),\n",
    "]\n",
    "\n",
    "correct = 0\n",
    "print(f\"{'Text':<55} | {'Predicted':<10} | {'Actual':<10} | OK?\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for text, actual in test_examples:\n",
    "    pred_id = model.predict([text])[0]\n",
    "    predicted = ID_TO_LABEL[int(pred_id)]\n",
    "    match = predicted == actual\n",
    "    correct += match\n",
    "    short = (text[:52] + \"...\") if len(text) > 52 else text\n",
    "    print(f\"{short:<55} | {predicted:<10} | {actual:<10} | {'Y' if match else 'N'}\")\n",
    "\n",
    "print(f\"\\nAccuracy: {correct}/{len(test_examples)} ({correct / len(test_examples) * 100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"sentiment_setfit_model\"\n",
    "model.save_pretrained(MODEL_DIR)\n",
    "print(f\"Model saved to '{MODEL_DIR}/'\")\n",
    "\n",
    "# Reload later with:\n",
    "# model = SetFitModel.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## What is ONNX?\n",
    "\n",
    "**ONNX** (Open Neural Network Exchange) is an **open standard format** for representing\n",
    "machine learning models. Think of it as a *\"PDF for ML models\"* — a universal file that\n",
    "any compatible runtime can execute.\n",
    "\n",
    "### The Problem\n",
    "\n",
    "You train in **PyTorch**, but need to deploy on:\n",
    "- A C++ backend server\n",
    "- A mobile app (iOS / Android)\n",
    "- A cloud function with minimal dependencies\n",
    "\n",
    "Each framework uses its own format (PyTorch `.pt`, TensorFlow `.pb`, etc.).\n",
    "ONNX bridges them all with **one universal `.onnx` file**.\n",
    "\n",
    "### What's Inside an `.onnx` File?\n",
    "\n",
    "```\n",
    "+---------------------------------------------+\n",
    "|              model.onnx                      |\n",
    "|                                              |\n",
    "|  +----------+   +-----------+   +----------+ |\n",
    "|  |  Embed   |-->| Attention |-->|  Linear  | |\n",
    "|  |  Lookup  |   |  Layers   |   |  Output  | |\n",
    "|  +----------+   +-----------+   +----------+ |\n",
    "|                                              |\n",
    "|  + Trained weights (learned parameters)      |\n",
    "|  + Input / output specs (shapes, dtypes)     |\n",
    "+---------------------------------------------+\n",
    "```\n",
    "\n",
    "The file stores the **computation graph** (every operation: matmul, softmax,\n",
    "layer norm, etc.) plus the trained weights.\n",
    "\n",
    "### Why Use ONNX?\n",
    "\n",
    "| Benefit | Details |\n",
    "|---------|---------|\n",
    "| **Speed** | ONNX Runtime applies graph optimizations (operator fusion, constant folding) — often **2-5x faster** than raw PyTorch |\n",
    "| **Portability** | Deploy anywhere: Linux, Windows, macOS, ARM, WebAssembly |\n",
    "| **Small footprint** | Production only needs `onnxruntime` (~50 MB) instead of PyTorch (~2 GB) |\n",
    "| **Hardware accel.** | Built-in CUDA, TensorRT, DirectML, OpenVINO, CoreML support |\n",
    "\n",
    "### ONNX Runtime\n",
    "\n",
    "**ONNX Runtime** is the inference engine that executes `.onnx` files. Developed\n",
    "by Microsoft, it's battle-tested in production at Bing, Office, and Xbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Export to ONNX\n",
    "\n",
    "A SetFit model has **two components**:\n",
    "\n",
    "| Component | What it does | Size | Export strategy |\n",
    "|-----------|-------------|------|----------------|\n",
    "| **Body** (Sentence Transformer) | Text -> embedding vector | ~80 MB | Export to ONNX |\n",
    "| **Head** (Logistic Regression) | Embedding -> label | ~1 KB | Pickle (sklearn) |\n",
    "\n",
    "We export the **body** (where 99% of compute happens) to ONNX,\n",
    "and pickle the lightweight head separately.\n",
    "\n",
    "```\n",
    "Text -> Tokenizer -> [ Transformer Body ] -> Mean Pool -> Normalize -> [ Head ] -> Label\n",
    "                      ^^^^^^^^^^^^^^^^^^                                ^^^^^^\n",
    "                      Export to ONNX                                    Pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# ===================================================================\n",
    "# Step 1: Extract the raw transformer from the SetFit model\n",
    "# ===================================================================\n",
    "# SetFit's model_body is a SentenceTransformer containing:\n",
    "#   [0] Transformer  — the HuggingFace model (does the heavy work)\n",
    "#   [1] Pooling      — mean pooling over token embeddings\n",
    "#   [2] Normalize    — L2 normalization (model-dependent)\n",
    "#\n",
    "# We need the raw transformer for ONNX export.\n",
    "\n",
    "transformer_model = model.model_body[0].auto_model\n",
    "tokenizer = model.model_body.tokenizer\n",
    "\n",
    "# Save separately so we can reload cleanly\n",
    "TRANSFORMER_DIR = \"sentiment_transformer\"\n",
    "transformer_model.save_pretrained(TRANSFORMER_DIR)\n",
    "tokenizer.save_pretrained(TRANSFORMER_DIR)\n",
    "\n",
    "print(f\"Transformer saved to '{TRANSFORMER_DIR}/'\")\n",
    "\n",
    "# ===================================================================\n",
    "# Step 2: Export the transformer to ONNX\n",
    "# ===================================================================\n",
    "# torch.onnx.export works by:\n",
    "#   1. Feeding a dummy input through the model\n",
    "#   2. Tracing every operation (matmul, softmax, layernorm, ...)\n",
    "#   3. Recording the traced graph + weights into a .onnx file\n",
    "\n",
    "ONNX_PATH = \"sentiment_model.onnx\"\n",
    "\n",
    "export_model = AutoModel.from_pretrained(TRANSFORMER_DIR)\n",
    "export_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_DIR)\n",
    "export_model.eval()\n",
    "\n",
    "# ONNX export requires tuple outputs, not dicts\n",
    "export_model.config.return_dict = False\n",
    "\n",
    "# Dummy input for tracing (actual values don't matter, only shapes do)\n",
    "dummy = export_tokenizer(\n",
    "    \"Sample sentence for tracing.\",\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        export_model,\n",
    "        # Model inputs (positional args to forward())\n",
    "        (dummy[\"input_ids\"], dummy[\"attention_mask\"]),\n",
    "        # Output path\n",
    "        ONNX_PATH,\n",
    "        # Name the inputs/outputs so we can reference them later\n",
    "        input_names=[\"input_ids\", \"attention_mask\"],\n",
    "        output_names=[\"last_hidden_state\", \"pooler_output\"],\n",
    "        # dynamic_axes lets the model accept variable-length inputs\n",
    "        # at runtime (not locked to the dummy input's shape)\n",
    "        dynamic_axes={\n",
    "            \"input_ids\":        {0: \"batch_size\", 1: \"seq_len\"},\n",
    "            \"attention_mask\":   {0: \"batch_size\", 1: \"seq_len\"},\n",
    "            \"last_hidden_state\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "            \"pooler_output\":    {0: \"batch_size\"},\n",
    "        },\n",
    "        opset_version=14,\n",
    "        do_constant_folding=True,  # fold constant ops at export time\n",
    "    )\n",
    "\n",
    "onnx_mb = os.path.getsize(ONNX_PATH) / (1024 * 1024)\n",
    "print(f\"ONNX model exported: {ONNX_PATH} ({onnx_mb:.1f} MB)\")\n",
    "\n",
    "# ===================================================================\n",
    "# Step 3: Save the classification head (sklearn LogisticRegression)\n",
    "# ===================================================================\n",
    "\n",
    "HEAD_PATH = \"sentiment_head.pkl\"\n",
    "with open(HEAD_PATH, \"wb\") as f:\n",
    "    pickle.dump(model.model_head, f)\n",
    "\n",
    "print(f\"Head saved: {HEAD_PATH}\")\n",
    "print(f\"\\nFiles needed for production inference (no PyTorch!):\")\n",
    "print(f\"  1. {ONNX_PATH}\")\n",
    "print(f\"  2. {HEAD_PATH}\")\n",
    "print(f\"  3. {TRANSFORMER_DIR}/  (tokenizer files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Inference with ONNX Runtime\n",
    "\n",
    "Now we can classify text **without PyTorch** — only `onnxruntime` and\n",
    "`transformers` (for the tokenizer) are needed.\n",
    "\n",
    "The pipeline reproduces what the SentenceTransformer does internally:\n",
    "\n",
    "```\n",
    "1. Tokenize          text -> input_ids, attention_mask   (AutoTokenizer)\n",
    "2. Transformer       input_ids -> hidden_states          (ONNX Runtime)\n",
    "3. Mean pooling      hidden_states -> sentence_embedding (NumPy)\n",
    "4. L2 normalize      normalize the embedding             (NumPy)\n",
    "5. Classify          embedding -> label                  (sklearn head)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Load the three inference components\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# 1. Tokenizer (text -> token IDs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentiment_transformer\")\n",
    "\n",
    "# 2. ONNX session (token IDs -> hidden states)\n",
    "session = ort.InferenceSession(\n",
    "    \"sentiment_model.onnx\",\n",
    "    providers=[\"CPUExecutionProvider\"],  # swap to \"CUDAExecutionProvider\" for GPU\n",
    ")\n",
    "\n",
    "# 3. Classification head (embedding -> label)\n",
    "with open(\"sentiment_head.pkl\", \"rb\") as f:\n",
    "    head = pickle.load(f)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Full inference function\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def predict_sentiment(texts):\n",
    "    \"\"\"Predict sentiment using the ONNX-exported model.\"\"\"\n",
    "\n",
    "    # 1) Tokenize — return NumPy arrays (no PyTorch needed)\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "\n",
    "    # 2) Run the ONNX transformer\n",
    "    outputs = session.run(\n",
    "        None,  # None = return all outputs\n",
    "        {\n",
    "            \"input_ids\": inputs[\"input_ids\"],\n",
    "            \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        },\n",
    "    )\n",
    "    hidden_states = outputs[0]  # (batch, seq_len, 384)\n",
    "\n",
    "    # 3) Mean pooling — average token vectors, ignoring padding\n",
    "    mask = np.expand_dims(inputs[\"attention_mask\"], axis=-1).astype(np.float32)\n",
    "    embeddings = (hidden_states * mask).sum(axis=1) / mask.sum(axis=1)  # (batch, 384)\n",
    "\n",
    "    # 4) L2 normalize — same as the SentenceTransformer's Normalize module\n",
    "    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    embeddings = embeddings / np.maximum(norms, 1e-12)\n",
    "\n",
    "    # 5) Classify with the sklearn head\n",
    "    predictions = head.predict(embeddings)\n",
    "    return [ID_TO_LABEL[int(p)] for p in predictions]\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Test it\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "test_texts = [\n",
    "    \"This movie was absolutely fantastic, I loved every minute!\",\n",
    "    \"The product broke on the first day, total garbage.\",\n",
    "    \"The meeting has been moved to Tuesday at 2 PM.\",\n",
    "    \"I'm so grateful for the amazing support team!\",\n",
    "    \"Worst experience ever, never coming back.\",\n",
    "]\n",
    "\n",
    "results = predict_sentiment(test_texts)\n",
    "\n",
    "for text, sentiment in zip(test_texts, results):\n",
    "    print(f\"  {sentiment:>8}  |  {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Benchmark: PyTorch vs ONNX Runtime\n",
    "\n",
    "Let's measure the speed difference on a batch of 150 texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "benchmark_texts = [\n",
    "    \"The service was exceptional and the staff was very friendly.\",\n",
    "    \"I regret purchasing this item, it doesn't work as advertised.\",\n",
    "    \"The order arrived on the scheduled delivery date.\",\n",
    "] * 50  # 150 texts\n",
    "\n",
    "# --- PyTorch (SetFit) ---\n",
    "setfit_model = SetFitModel.from_pretrained(\"sentiment_setfit_model\")\n",
    "\n",
    "start = time.perf_counter()\n",
    "_ = setfit_model.predict(benchmark_texts)\n",
    "pytorch_time = time.perf_counter() - start\n",
    "\n",
    "# --- ONNX Runtime ---\n",
    "start = time.perf_counter()\n",
    "_ = predict_sentiment(benchmark_texts)\n",
    "onnx_time = time.perf_counter() - start\n",
    "\n",
    "# --- Results ---\n",
    "print(f\"Texts processed : {len(benchmark_texts)}\")\n",
    "print(f\"PyTorch (SetFit) : {pytorch_time:.3f}s  ({len(benchmark_texts) / pytorch_time:.0f} texts/sec)\")\n",
    "print(f\"ONNX Runtime     : {onnx_time:.3f}s  ({len(benchmark_texts) / onnx_time:.0f} texts/sec)\")\n",
    "print(f\"Speedup          : {pytorch_time / onnx_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Step | What we did |\n",
    "|------|------------|\n",
    "| **1. Data** | Created 30 labeled examples (10 per class) |\n",
    "| **2. Train** | Fine-tuned `all-MiniLM-L6-v2` with SetFit in ~2 minutes on CPU |\n",
    "| **3. Export** | Used `torch.onnx.export` to convert the transformer body to `.onnx` |\n",
    "| **4. Inference** | Ran the ONNX model with `onnxruntime` — no PyTorch required |\n",
    "| **5. Benchmark** | Measured the speedup from ONNX Runtime optimizations |\n",
    "\n",
    "### Production deployment checklist\n",
    "\n",
    "You only need **three files** + two lightweight packages:\n",
    "\n",
    "```\n",
    "Files:\n",
    "  sentiment_model.onnx          # transformer body\n",
    "  sentiment_head.pkl            # classification head\n",
    "  sentiment_transformer/        # tokenizer files\n",
    "\n",
    "Packages:\n",
    "  pip install onnxruntime transformers\n",
    "```\n",
    "\n",
    "No PyTorch (~2 GB) needed in production.\n",
    "\n",
    "### Alternative: `optimum` (one-liner export)\n",
    "\n",
    "For a higher-level approach, Hugging Face's [optimum](https://huggingface.co/docs/optimum) library\n",
    "can export and run ONNX models with less manual work:\n",
    "\n",
    "```python\n",
    "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
    "\n",
    "ort_model = ORTModelForFeatureExtraction.from_pretrained(\n",
    "    \"sentiment_transformer\", export=True\n",
    ")\n",
    "ort_model.save_pretrained(\"sentiment_onnx\")\n",
    "```\n",
    "\n",
    "This handles the export, dynamic axes, and optimization automatically."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
